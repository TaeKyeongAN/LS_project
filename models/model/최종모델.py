import warnings
import numpy as np
import pandas as pd
from catboost import CatBoostRegressor
from lightgbm import LGBMRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import TimeSeriesSplit 
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import HuberRegressor # â­ HuberRegressor íŠœë‹ ëŒ€ìƒ
from sklearn.ensemble import HistGradientBoostingRegressor

warnings.filterwarnings("ignore")

# -----------------------------
# 0) Load
# -----------------------------
# íŒŒì¼ ê²½ë¡œë¥¼ ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ì¡°ì •í•˜ì„¸ìš”.
train = pd.read_csv("./data/train.csv")
test = pd.read_csv("./data/test.csv")

# -----------------------------
# 1) ì „ì—­ ìƒìˆ˜ ë° ì‹œê°„ í”¼ì²˜ ì •ì˜ 
# -----------------------------
REF_DATE = pd.Timestamp("2024-10-24")
MAX_PRICE = 1.0
MID_PRICE = 0.6
LIGHT_PRICE = 0.4

def adjust_hour(dt):
    if pd.isna(dt): return np.nan
    return (dt.hour - 1) % 24 if dt.minute == 0 else dt.hour

def get_tou_relative_price(m, h, period_flag):
    if period_flag == 1: 
        if m in [7, 8]:  # Summer
            if (10 <= h < 12) or (13 <= h < 17): return MAX_PRICE
            if (9 <= h < 10) or (12 <= h < 13) or (17 <= h < 22): return MID_PRICE
            return LIGHT_PRICE
        elif m in [12, 1, 2]:  # Winter
            if (9 <= h < 12) or (17 <= h < 22): return MAX_PRICE
            if (12 <= h < 17) or (22 <= h < 23): return MID_PRICE
            return LIGHT_PRICE
        else:  # Spring/Fall
            if (9 <= h < 23): return MID_PRICE
            return LIGHT_PRICE
    else: 
        if m in [7, 8]:  # Summer
            if (10 <= h < 12) or (13 <= h < 17): return MAX_PRICE
            if (9 <= h < 10) or (12 <= h < 13) or (17 <= h < 22): return MID_PRICE
            return LIGHT_PRICE
        elif m in [12, 1, 2]:  # Winter
            if (9 <= h < 12) or (17 <= h < 22): return MAX_PRICE
            if (12 <= h < 17) or (22 <= h < 23): return MID_PRICE
            return LIGHT_PRICE
        else:  # Spring/Fall
            if (9 <= h < 23): return MID_PRICE
            return LIGHT_PRICE

def enrich(df):
    df["ì¸¡ì •ì¼ì‹œ"] = pd.to_datetime(df["ì¸¡ì •ì¼ì‹œ"], errors="coerce")
    df["ì›”"] = df["ì¸¡ì •ì¼ì‹œ"].dt.month
    df["ì¼"] = df["ì¸¡ì •ì¼ì‹œ"].dt.day
    df["ìš”ì¼"] = df["ì¸¡ì •ì¼ì‹œ"].dt.dayofweek
    df["ë‚ ì§œ"] = df['ì¸¡ì •ì¼ì‹œ'].dt.date 
    df["ì‹œê°„"] = df["ì¸¡ì •ì¼ì‹œ"].apply(adjust_hour)
    df["ì£¼ë§ì—¬ë¶€"] = (df["ìš”ì¼"] >= 5).astype(int)
    df["ê²¨ìš¸ì—¬ë¶€"] = df["ì›”"].isin([11, 12, 1, 2]).astype(int) 
    df["period_flag"] = (df["ì¸¡ì •ì¼ì‹œ"] >= REF_DATE).astype(int)
    df["sin_time"] = np.sin(2 * np.pi * df["ì‹œê°„"] / 24)
    df["cos_time"] = np.cos(2 * np.pi * df["ì‹œê°„"] / 24)
    df["tou_relative_price"] = df.apply(lambda row: get_tou_relative_price(row["ì›”"], row["ì‹œê°„"], row["period_flag"]), axis=1)
    df["tou_load_index"] = df.apply(lambda row: 3 if row["tou_relative_price"] == MAX_PRICE else (2 if row["tou_relative_price"] == MID_PRICE else 1), axis=1)
    df["tou_price_code"] = df["period_flag"].astype(str) + "_" + df["tou_load_index"].astype(str)
    df["sin_day"] = np.sin(2 * np.pi * df["ì¼"] / 31)
    df["cos_day"] = np.cos(2 * np.pi * df["ì¼"] / 31)
    df["sin_month"] = np.sin(2 * np.pi * df["ì›”"] / 12)
    df["cos_month"] = np.cos(2 * np.pi * df["ì›”"] / 12)
    return df

train = enrich(train).sort_values("ì¸¡ì •ì¼ì‹œ").reset_index(drop=True)
test = enrich(test).sort_values("ì¸¡ì •ì¼ì‹œ").reset_index(drop=True)

# -----------------------------
# 2) ì¸ì½”ë”© 
# -----------------------------
le_job = LabelEncoder()
train["ì‘ì—…ìœ í˜•_encoded"] = le_job.fit_transform(train["ì‘ì—…ìœ í˜•"].astype(str))
def safe_transform(le, series, mode_val):
    series_mapped = series.astype(str).map(lambda s: '-1' if s not in le.classes_ else s)
    return le.transform(series_mapped.replace('-1', mode_val))

test["ì‘ì—…ìœ í˜•_encoded"] = safe_transform(le_job, test["ì‘ì—…ìœ í˜•"], train["ì‘ì—…ìœ í˜•"].mode()[0])

le_tou = LabelEncoder()
train["tou_price_code_encoded"] = le_tou.fit_transform(train["tou_price_code"].astype(str))
test["tou_price_code_encoded"] = safe_transform(le_tou, test["tou_price_code"], train["tou_price_code"].mode()[0])

train["ì‹œê°„_ì‘ì—…ìœ í˜•"] = train["ì‹œê°„"].astype(str) + "_" + train["ì‘ì—…ìœ í˜•_encoded"].astype(str)
test["ì‹œê°„_ì‘ì—…ìœ í˜•"] = test["ì‹œê°„"].astype(str) + "_" + test["ì‘ì—…ìœ í˜•_encoded"].astype(str)
le_tj = LabelEncoder()
train["ì‹œê°„_ì‘ì—…ìœ í˜•_encoded"] = le_tj.fit_transform(train["ì‹œê°„_ì‘ì—…ìœ í˜•"])
test["ì‹œê°„_ì‘ì—…ìœ í˜•_encoded"] = safe_transform(le_tj, test["ì‹œê°„_ì‘ì—…ìœ í˜•"], train["ì‹œê°„_ì‘ì—…ìœ í˜•"].mode()[0])


# -----------------------------
# 2.5) ìš”ê¸ˆì ìš©ì „ë ¥ (Demand Charge) ì‹¤ì œê°’ ê³„ì‚°
# -----------------------------
def calculate_demand_charge_true(df):
    df["í”¼ìƒì „ë ¥_sim"] = np.sqrt(df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"]**2 + df["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"]**2)
    df["ìš”ê¸ˆì ìš©ì „ë ¥_kW_true"] = 0.0
    demand_months = [12, 1, 2, 7, 8, 9] 
    
    for idx in df.index:
        current_date = df.loc[idx, "ì¸¡ì •ì¼ì‹œ"]
        start_date = current_date - pd.DateOffset(months=12)
        history_df = df.loc[(df["ì¸¡ì •ì¼ì‹œ"] >= start_date) & 
                            (df["ì¸¡ì •ì¼ì‹œ"] < current_date) & 
                            (df["ì›”"].isin(demand_months))]
        
        current_max_demand = 0.0
        if not history_df.empty:
            max_demand = history_df["í”¼ìƒì „ë ¥_sim"].max()
            current_max_demand = max(current_max_demand, max_demand)

        if current_date.month in demand_months:
             current_max_demand = max(current_max_demand, df.loc[idx, "í”¼ìƒì „ë ¥_sim"])

        df.loc[idx, "ìš”ê¸ˆì ìš©ì „ë ¥_kW_true"] = current_max_demand

    df.fillna(method='bfill', inplace=True)
    return df.fillna(0)

train = calculate_demand_charge_true(train)

# -----------------------------
# 3) Stage1: ì „ë ¥íŠ¹ì„± ë° ìš”ê¸ˆì ìš©ì „ë ¥ ì˜ˆì¸¡ 
# -----------------------------
targets_s1 = ["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)", "ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)", "ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)", 
              "ì§€ìƒì—­ë¥ (%)", "ì§„ìƒì—­ë¥ (%)", "ìš”ê¸ˆì ìš©ì „ë ¥_kW_true", "íƒ„ì†Œë°°ì¶œëŸ‰(tCO2)"] 
feat_s1 = ["ì›”","ì¼","ìš”ì¼","ì‹œê°„","ì£¼ë§ì—¬ë¶€","ê²¨ìš¸ì—¬ë¶€","period_flag",
           "sin_time","cos_time","sin_day", "cos_day", "sin_month", "cos_month",
           "ì‘ì—…ìœ í˜•_encoded", "tou_relative_price", "tou_price_code_encoded", "ì‹œê°„_ì‘ì—…ìœ í˜•_encoded"] 

stage1_models = {
    "ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)": LGBMRegressor(n_estimators=2500, learning_rate=0.012, num_leaves=128, random_state=42), 
    "ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)": CatBoostRegressor(iterations=2000, learning_rate=0.03, depth=7, verbose=0, random_seed=42), 
    "ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)": CatBoostRegressor(iterations=2000, learning_rate=0.03, depth=7, verbose=0, random_seed=42), 
    "ì§€ìƒì—­ë¥ (%)": LGBMRegressor(n_estimators=2000, learning_rate=0.02, num_leaves=96, random_state=42), 
    "ì§„ìƒì—­ë¥ (%)": LGBMRegressor(n_estimators=2000, learning_rate=0.02, num_leaves=96, random_state=42), 
    "ìš”ê¸ˆì ìš©ì „ë ¥_kW_true": LGBMRegressor(n_estimators=2500, learning_rate=0.008, num_leaves=64, random_state=42, 
                                          subsample=0.8, colsample_bytree=0.8,
                                          objective='huber', metric='mae', alpha=0.9),
    "íƒ„ì†Œë°°ì¶œëŸ‰(tCO2)": LGBMRegressor(n_estimators=2000, learning_rate=0.012, num_leaves=64, random_state=42), 
}

tscv = TimeSeriesSplit(n_splits=5)
stage1_oof = pd.DataFrame(index=train.index)
stage1_test_pred = pd.DataFrame(index=test.index)
train_targets_true = train[targets_s1].copy()

for tgt in targets_s1:
    oof_pred = np.full(len(train), np.nan, dtype=float)
    model = stage1_models[tgt]
    
    current_target = train_targets_true[tgt].copy()
    is_demand_target = (tgt == "ìš”ê¸ˆì ìš©ì „ë ¥_kW_true")
    if is_demand_target:
        current_target = np.log1p(current_target)

    for fold, (tr_idx, va_idx) in enumerate(tscv.split(train), start=1):
        fold_model = model.__class__(**model.get_params())
        fold_model.fit(train.iloc[tr_idx][feat_s1], current_target.iloc[tr_idx])
        oof_pred[va_idx] = fold_model.predict(train.iloc[va_idx][feat_s1])

    missing = np.isnan(oof_pred)
    if missing.any():
        full_model = model.__class__(**model.get_params())
        full_model.fit(train[feat_s1], current_target)
        oof_pred[missing] = full_model.predict(train.loc[missing, feat_s1])
        
    if is_demand_target:
        oof_pred = np.expm1(oof_pred).clip(min=0) 

    stage1_oof[tgt] = oof_pred
    
    final_model = model.__class__(**model.get_params())
    final_model.fit(train[feat_s1], current_target)
    test_pred = final_model.predict(test[feat_s1])
    
    if is_demand_target:
        test_pred = np.expm1(test_pred).clip(min=0) 
        
    stage1_test_pred[tgt] = test_pred

for tgt in targets_s1:
    new_col_name = "ìš”ê¸ˆì ìš©ì „ë ¥_kW" if tgt == "ìš”ê¸ˆì ìš©ì „ë ¥_kW_true" else tgt
    train[new_col_name] = stage1_oof[tgt]
    test[new_col_name] = stage1_test_pred[tgt]
    
train["í”¼ìƒì „ë ¥_sim"] = np.sqrt(train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"]**2 + train["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"]**2)
test["í”¼ìƒì „ë ¥_sim"] = np.sqrt(test["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"]**2 + test["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"]**2)


# -----------------------------
# 3.5) Stage1 ì˜ˆì¸¡ê°’ í›„ì²˜ë¦¬ ë° 4-6) í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ 
# -----------------------------
def post_process_stage1(df):
    P = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"]
    Q = df["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"]
    safe_denominator = np.sqrt(P**2 + Q**2) + 1e-6
    df["PF_recalc"] = 100 * P / safe_denominator
    df["PF_recalc"] = df["PF_recalc"].clip(upper=100.0) 
    df["PF_diff"] = df["PF_recalc"] - df["ì§€ìƒì—­ë¥ (%)"]
    is_low_kwh = (df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] < 0.5)
    df["PF_recalc"] = np.where(is_low_kwh, 95.0, df["PF_recalc"])
    df["PF_diff"] = np.where(is_low_kwh, 0.0, df["PF_diff"])
    return df

train = post_process_stage1(train)
test = post_process_stage1(test)

def add_pf_features_regulated(df):
    df["ìœ íš¨ì—­ë¥ (%)"] = df[["ì§€ìƒì—­ë¥ (%)", "ì§„ìƒì—­ë¥ (%)"]].max(axis=1)
    df["ì—­ë¥ _íŒ¨ë„í‹°ìœ¨"] = (90 - df["ìœ íš¨ì—­ë¥ (%)"]).clip(lower=0) * 0.01
    df["ì—­ë¥ _ë³´ìƒìœ¨"] = (df["ìœ íš¨ì—­ë¥ (%)"] - 90).clip(lower=0) * 0.005
    df["ì—­ë¥ _ì¡°ì •ìš”ìœ¨"] = df["ì—­ë¥ _ë³´ìƒìœ¨"] - df["ì—­ë¥ _íŒ¨ë„í‹°ìœ¨"]
    df["ì£¼ê°„ì—¬ë¶€"] = df["ì‹œê°„"].isin(range(9, 23)).astype(int)
    df["ì§€ìƒì—­ë¥ _ë³´ì •"] = df["PF_recalc"].clip(lower=60)
    df["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"] = np.where(df["ì£¼ê°„ì—¬ë¶€"] == 1, df["ì§€ìƒì—­ë¥ _ë³´ì •"].clip(upper=95), df["ì§€ìƒì—­ë¥ _ë³´ì •"])
    df["ì—­ë¥ ë¶€ì¡±í­_94"] = (94 - df["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"]).clip(lower=0) * df["ì£¼ê°„ì—¬ë¶€"]
    df["ì—­ë¥ ë¶€ì¡±í­_90"] = (90 - df["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"]).clip(lower=0) * df["ì£¼ê°„ì—¬ë¶€"]
    df["ì—­ë¥ ë¶€ì¡±í­_92"] = (92 - df["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"]).clip(lower=0) * df["ì£¼ê°„ì—¬ë¶€"]
    df["ì—­ë¥ ìš°ìˆ˜"] = (df["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"] >= 95).astype(int) 
    df["ì•¼ê°„ì—¬ë¶€"] = (1 - df["ì£¼ê°„ì—¬ë¶€"]).astype(int)
    df["ì§„ìƒì—­ë¥ _í˜ë„í‹°"] = (95 - df["ì§„ìƒì—­ë¥ (%)"]).clip(lower=0) * df["ì•¼ê°„ì—¬ë¶€"]
    df["ë²•ì í˜ë„í‹°"] = ((df["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"] < 90) & (df["ì£¼ê°„ì—¬ë¶€"] == 1)).astype(int)
    df["ì‹¤ì§ˆìœ„í—˜"] = ((df["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"] < 94) & (df["ì£¼ê°„ì—¬ë¶€"] == 1)).astype(int)
    df["ê·¹ì €ì—­ë¥ "] = ((df["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"] < 85) & (df["ì£¼ê°„ì—¬ë¶€"] == 1)).astype(int)
    return df
train = add_pf_features_regulated(train)
test = add_pf_features_regulated(test)

def add_lag_roll(df, hist_data, is_train=True):
    df["kwh_lag1"] = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1)
    df["kwh_lag24"] = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(24)
    df["kwh_roll24_mean"] = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1).rolling(24).mean()
    df["kwh_roll24_std"] = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].shift(1).rolling(24).std().fillna(0)
    if is_train:
        df.fillna(method='bfill', inplace=True)
        return df.fillna(0)
    else: 
        hist_data_kwh = list(hist_data["kwh"].values.astype(float))
        for i in range(len(df)):
            df.loc[df.index[i], "kwh_lag1"] = hist_data_kwh[-1] if len(hist_data_kwh) >= 1 else 0
            df.loc[df.index[i], "kwh_lag24"] = hist_data_kwh[-24] if len(hist_data_kwh) >= 24 else 0
            arr24 = np.array(hist_data_kwh[-24:])
            df.loc[df.index[i], "kwh_roll24_mean"] = arr24.mean() if arr24.size > 0 else 0
            df.loc[df.index[i], "kwh_roll24_std"] = arr24.std() if arr24.size > 1 else 0
            hist_data_kwh.append(df.loc[df.index[i], "ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"])
        return df
hist_data_train = {"kwh": train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"]}
hist_data_test = {"kwh": train["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].copy()}
train = add_lag_roll(train, hist_data_train, is_train=True)
test = add_lag_roll(test, hist_data_test, is_train=False)

kwh_mean_day_hour = train.groupby(["ìš”ì¼", "ì‹œê°„"])["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"].mean().reset_index()
kwh_mean_day_hour.rename(columns={"ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)": "kwh_ìš”ì¼_ì‹œê°„_í‰ê· "}, inplace=True)
train = pd.merge(train, kwh_mean_day_hour, on=["ìš”ì¼", "ì‹œê°„"], how="left")
test = pd.merge(test, kwh_mean_day_hour, on=["ìš”ì¼", "ì‹œê°„"], how="left")

def add_advanced_features_hybrid(df, train_means=None):
    df["ë¬´íš¨ìœ íš¨ë¹„ìœ¨"] = df["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"] / (df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] + 1e-6)
    df["ë¶€í•˜ì—­ë¥ ê³±"] = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] * df["ì—­ë¥ ë¶€ì¡±í­_94"] 
    df["ì—­ë¥ ë‹¹ì „ë ¥"] = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] / (df["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"] + 1e-6) 
    df["ê°€ì„ìœ„í—˜"] = ((df["ì›”"].isin([9, 10])) & (df["ì‹¤ì§ˆìœ„í—˜"] == 1)).astype(int)
    df["ë™ì ˆê¸°ì•ˆì •"] = ((df["ê²¨ìš¸ì—¬ë¶€"] == 1) & (df["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"] >= 94)).astype(int)
    if train_means: 
        df["ì—­ë¥ _ì›”í‰ê· "] = df["ì›”"].map(train_means["ì—­ë¥ _ì›”í‰ê· "])
        df["ì—­ë¥ _ì›”í‰ê· "].fillna(train_means["ì—­ë¥ _ì›”í‰ê· "].mean(), inplace=True) 
    else: 
        df["ì—­ë¥ _ì›”í‰ê· "] = df.groupby("ì›”")["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"].transform("mean")
    df["ì—­ë¥ _ì›”í‰ê· ì°¨ì´"] = df["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"] - df["ì—­ë¥ _ì›”í‰ê· "]
    df["kwh_roll24_cv"] = df["kwh_roll24_std"] / (df["kwh_roll24_mean"] + 1e-6)
    df["kwh_ë³€í™”ìœ¨_24h"] = ((df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] - df["kwh_lag24"]) / (df["kwh_lag24"] + 1e-6))
    df["ì „ë ¥ê¸‰ë“±"] = (df["kwh_ë³€í™”ìœ¨_24h"] > 0.5).astype(int)
    df["kwh_ì‹œê°„ëŒ€ë¹„_ìš”ì¼"] = df["ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)"] / (df["kwh_ìš”ì¼_ì‹œê°„_í‰ê· "] + 1e-6)
    df.drop("kwh_ìš”ì¼_ì‹œê°„_í‰ê· ", axis=1, inplace=True)
    df["ì´ë¬´íš¨ì „ë ¥"] = df["ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"] + df["ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)"]
    df["ìš”ê¸ˆì ìš©ì „ë ¥_ì°¨ì´_ë¹„ìœ¨"] = (df["ìš”ê¸ˆì ìš©ì „ë ¥_kW"] - df["í”¼ìƒì „ë ¥_sim"]) / (df["ìš”ê¸ˆì ìš©ì „ë ¥_kW"] + 1e-6)
    return df
train_means_for_test = {"ì—­ë¥ _ì›”í‰ê· ": train.groupby("ì›”")["ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½"].mean()}
train = add_advanced_features_hybrid(train)
test = add_advanced_features_hybrid(test, train_means=train_means_for_test)

def add_time_dayofweek_features(df):
    df['hour_workday'] = df['ì‹œê°„'] * (1 - df['ì£¼ë§ì—¬ë¶€'])
    df['hour_weekend'] = df['ì‹œê°„'] * df['ì£¼ë§ì—¬ë¶€']
    for d in range(7):
        df[f'hour_day_{d}'] = df['ì‹œê°„'] * (df['ìš”ì¼'] == d).astype(int)
    return df
train = add_time_dayofweek_features(train)
test = add_time_dayofweek_features(test)

def create_daily_worktype_sequence(df, is_train=True):
    daily_sequence = df.groupby('ë‚ ì§œ')['ì‘ì—…ìœ í˜•_encoded'].apply(
        lambda x: '_'.join(x.astype(str).tolist())
    ).reset_index(name='ì‘ì—…ìœ í˜•_ì‹œí€€ìŠ¤')
    if is_train:
        global le_sequence
        le_sequence = LabelEncoder()
        daily_sequence['ì‘ì—…ìœ í˜•_ì¼ë³„_ì‹œí€€ìŠ¤_ID'] = le_sequence.fit_transform(daily_sequence['ì‘ì—…ìœ í˜•_ì‹œí€€ìŠ¤'])
    else:
        daily_sequence['ì‘ì—…ìœ í˜•_ì¼ë³„_ì‹œí€€ìŠ¤_ID'] = safe_transform(le_sequence, daily_sequence['ì‘ì—…ìœ í˜•_ì‹œí€€ìŠ¤'], le_sequence.classes_[0])
    df = pd.merge(df, daily_sequence[['ë‚ ì§œ', 'ì‘ì—…ìœ í˜•_ì¼ë³„_ì‹œí€€ìŠ¤_ID']], on='ë‚ ì§œ', how='left')
    df['ì‘ì—…ìœ í˜•_ì¼ë³„_ì‹œí€€ìŠ¤_ID'] = df['ì‘ì—…ìœ í˜•_ì¼ë³„_ì‹œí€€ìŠ¤_ID'].astype(int)
    return df

train = create_daily_worktype_sequence(train, is_train=True)
test = create_daily_worktype_sequence(test, is_train=False)


# -----------------------------
# 7) Stage2 Feature Set (â­ ë¶ˆì•ˆì •í–ˆë˜ kwh_sum_4h í”¼ì²˜ ì œê±°)
# -----------------------------
all_features = [
    "ì›”","ì¼","ìš”ì¼","ì‹œê°„","ì£¼ë§ì—¬ë¶€","ê²¨ìš¸ì—¬ë¶€","period_flag", "sin_day", "sin_month", "cos_month",
    "ì‘ì—…ìœ í˜•_encoded", "tou_relative_price", "tou_price_code_encoded", "ì‹œê°„_ì‘ì—…ìœ í˜•_encoded",
    "ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)","ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)","ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)", "ì§„ìƒì—­ë¥ (%)", "ìœ íš¨ì—­ë¥ (%)", "ì—­ë¥ _ì¡°ì •ìš”ìœ¨",
    "ì§€ìƒì—­ë¥ _ë³´ì •", "ì§€ìƒì—­ë¥ _ì£¼ê°„í´ë¦½", "ì£¼ê°„ì—¬ë¶€", "ì•¼ê°„ì—¬ë¶€", "ì‹¤ì§ˆìœ„í—˜", "ë²•ì í˜ë„í‹°", "ê·¹ì €ì—­ë¥ ", 
    "ì—­ë¥ ë¶€ì¡±í­_94", "ì—­ë¥ ë¶€ì¡±í­_92", "PF_recalc", "PF_diff", 
    "ë¬´íš¨ìœ íš¨ë¹„ìœ¨","ë¶€í•˜ì—­ë¥ ê³±","ì—­ë¥ _ì›”í‰ê· ", "ì´ë¬´íš¨ì „ë ¥", "ì—­ë¥ ë‹¹ì „ë ¥", "ì§„ìƒì—­ë¥ _í˜ë„í‹°", "ê°€ì„ìœ„í—˜", "ë™ì ˆê¸°ì•ˆì •",
    "ì—­ë¥ _ì›”í‰ê· ì°¨ì´","kwh_roll24_cv","kwh_lag1", "kwh_ë³€í™”ìœ¨_24h", "ì „ë ¥ê¸‰ë“±", 
    "kwh_lag24","kwh_roll24_mean","kwh_roll24_std", "kwh_ì‹œê°„ëŒ€ë¹„_ìš”ì¼", 
    "ìš”ê¸ˆì ìš©ì „ë ¥_kW", "í”¼ìƒì „ë ¥_sim", "hour_workday", "hour_weekend",
    "hour_day_0", "hour_day_1", "hour_day_2", "hour_day_3", "hour_day_4", "hour_day_5", "hour_day_6",
    "íƒ„ì†Œë°°ì¶œëŸ‰(tCO2)", "ì‘ì—…ìœ í˜•_ì¼ë³„_ì‹œí€€ìŠ¤_ID", "ìš”ê¸ˆì ìš©ì „ë ¥_ì°¨ì´_ë¹„ìœ¨"
]
feat_s2 = all_features


# -----------------------------
# 8) Stage2 í•™ìŠµ (â­ Huber Regressor epsilon íŠœë‹)
# -----------------------------
X_all = train[feat_s2].copy()
y_all = train["ì „ê¸°ìš”ê¸ˆ(ì›)"].copy()
y_all_log = np.log1p(y_all)
X_te = test[feat_s2].copy()

LGB_PARAMS = dict(n_estimators=2500, learning_rate=0.015, num_leaves=75, subsample=0.8, colsample_bytree=0.8, reg_alpha=5, reg_lambda=6, random_state=42, n_jobs=-1)
XGB_PARAMS = dict(n_estimators=2500, learning_rate=0.015, max_depth=6, subsample=0.8, colsample_bytree=0.8, reg_lambda=6, reg_alpha=3, random_state=42, n_jobs=-1)
CAT_PARAMS = dict(iterations=2000, learning_rate=0.018, depth=7, l2_leaf_reg=8, random_seed=42, verbose=0, thread_count=-1)
HGB_PARAMS = dict(max_iter=2000, learning_rate=0.018, max_leaf_nodes=63, random_state=42, loss='absolute_error')

base_models = {
    "lgb": LGBMRegressor(**LGB_PARAMS),
    "xgb": XGBRegressor(**XGB_PARAMS),
    "cat": CatBoostRegressor(**CAT_PARAMS),
    "hgb": HistGradientBoostingRegressor(**HGB_PARAMS) 
}

# â­ íŠœë‹: epsilonì„ 1.35ì—ì„œ 1.30ìœ¼ë¡œ ë‚®ì¶° ì´ìƒì¹˜ ì²˜ë¦¬ë¥¼ ì—„ê²©í•˜ê²Œ í•¨
meta_learner = HuberRegressor(epsilon=1.30) 
tscv_s2 = TimeSeriesSplit(n_splits=5) 

oof_preds_s2 = pd.DataFrame(index=X_all.index, columns=base_models.keys(), dtype=float)
test_preds_s2 = np.zeros((len(X_te), len(base_models)))

print(f"\nğŸš€ Stage 2 ëª¨ë¸ í•™ìŠµ ë° OOF ì˜ˆì¸¡ ìƒì„± ì‹œì‘ (5-Fold, Estimator 2000-2500)...")
for fold, (tr_idx, va_idx) in enumerate(tscv_s2.split(X_all), start=1):
    print(f"--- Fold {fold} ---")
    X_tr, X_va = X_all.iloc[tr_idx], X_all.iloc[va_idx]
    y_tr_log = y_all_log.iloc[tr_idx]

    fold_test_preds = [] 

    for name, model in base_models.items():
        print(f" Â Training {name}...")
        fold_model = model.__class__(**model.get_params())
        
        if name == 'hgb':
            X_tr_hgb = X_tr.rename(columns=lambda x: str(x).replace('[', '').replace(']', ''))
            X_va_hgb = X_va.rename(columns=lambda x: str(x).replace('[', '').replace(']', ''))
            fold_model.fit(X_tr_hgb, y_tr_log)
            oof_pred = fold_model.predict(X_va_hgb)
        else:
            fold_model.fit(X_tr, y_tr_log)
            oof_pred = fold_model.predict(X_va)
        
        oof_preds_s2.iloc[va_idx, list(base_models.keys()).index(name)] = oof_pred
        
        if name == 'hgb':
            X_te_hgb = X_te.rename(columns=lambda x: str(x).replace('[', '').replace(']', ''))
            fold_test_preds.append(fold_model.predict(X_te_hgb))
        else:
            fold_test_preds.append(fold_model.predict(X_te))

    test_preds_s2 += np.mean(fold_test_preds, axis=0)[:, np.newaxis] / tscv_s2.n_splits

print("\nâœ… OOF ì˜ˆì¸¡ ìƒì„± ì™„ë£Œ.")

oof_valid_idx = oof_preds_s2.dropna().index
print(f"\nğŸ§  Meta-Learner ({meta_learner.__class__.__name__}) í•™ìŠµ ì‹œì‘ (ë°ì´í„° {len(oof_valid_idx)}ê°œ, epsilon=1.30)...")
meta_test_input = pd.DataFrame(test_preds_s2, columns=base_models.keys(), index=X_te.index)

meta_learner.fit(oof_preds_s2.loc[oof_valid_idx], y_all_log.loc[oof_valid_idx])
print(f"âœ… Meta-Learner í•™ìŠµ ì™„ë£Œ.")

# ìµœì¢… Test ì˜ˆì¸¡
print("\nğŸ§ª ìµœì¢… Test ì˜ˆì¸¡ ìƒì„±...")
pred_te_log = meta_learner.predict(meta_test_input)
pred_te = np.expm1(pred_te_log)

# OOF ê²€ì¦ ì ìˆ˜ ê³„ì‚°
oof_pred_final_log = meta_learner.predict(oof_preds_s2.loc[oof_valid_idx])
oof_pred_final = np.expm1(oof_pred_final_log)
oof_mae = mean_absolute_error(y_all.loc[oof_valid_idx], oof_pred_final)
oof_r2 = r2_score(y_all.loc[oof_valid_idx], oof_pred_final)
print(f"\nğŸ“Š OOF ê²€ì¦ (Stacking): MAE={oof_mae:.2f} | RÂ²={oof_r2:.4f}")


# -----------------------------
# 9) í›„ì²˜ë¦¬ ë° ì œì¶œ
# -----------------------------
# ì˜ˆì¸¡ ë²”ìœ„ í´ë¦¬í•‘
low, high = np.percentile(pred_te, [0.01, 99.9]) 
pred_te = np.clip(pred_te, low, high)
pred_te = np.clip(pred_te, a_min=500, a_max=450000) 

submission = pd.DataFrame({"id": test["id"], "target": pred_te})
submission.to_csv("submission_737_hubertuning_final.csv", index=False) 
print("\nğŸ’¾ submission_737_hubertuning_final.csv ì €ì¥ ì™„ë£Œ! (ìµœì¢… íŠœë‹ ì ìš©)")
print(f"ì˜ˆì¸¡ ë²”ìœ„: {pred_te.min():.2f} ~ {pred_te.max():.2f}")
print(f"ì˜ˆì¸¡ í‰ê· : {pred_te.mean():.2f}")

# -----------------------------
# 10) ëª¨ë¸ ì‚¬í›„ ë¶„ì„ ì‹œê°í™”
# -----------------------------
from pathlib import Path

if __name__ == "__main__":
    try:
        import matplotlib.pyplot as plt
        import seaborn as sns
        from matplotlib.ticker import MaxNLocator
        from matplotlib import font_manager
    except ImportError as exc:
        print(f"\nâš ï¸ ì‹œê°í™” íŒ¨í‚¤ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ì–´ ê·¸ë˜í”„ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤: {exc}")
    else:
        sns.set_style("whitegrid")
        plt.rcParams["axes.unicode_minus"] = False

        # í•œê¸€ í°íŠ¸ ì„¤ì • (í™˜ê²½ì— ì¡´ì¬í•˜ëŠ” ì²« ë²ˆì§¸ í°íŠ¸ ì„ íƒ)
        available_fonts = {f.name for f in font_manager.fontManager.ttflist}
        for font_name in ["Malgun Gothic", "NanumGothic", "AppleGothic"]:
            if font_name in available_fonts:
                plt.rcParams["font.family"] = font_name
                break

        output_dir = Path("model_insights")
        output_dir.mkdir(parents=True, exist_ok=True)

        def save_fig(fig, path: Path):
            fig.savefig(path, dpi=160, bbox_inches="tight")
            plt.close(fig)
            print(f"ğŸ“ ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ -> {path}")

        # Stage1 í’ˆì§ˆ ìš”ì•½ ì‹œê°í™”
        stage1_targets_for_plot = [
            "ì „ë ¥ì‚¬ìš©ëŸ‰(kWh)",
            "ì§€ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)",
            "ì§„ìƒë¬´íš¨ì „ë ¥ëŸ‰(kVarh)",
            "ì§€ìƒì—­ë¥ (%)",
            "ì§„ìƒì—­ë¥ (%)",
            "ìš”ê¸ˆì ìš©ì „ë ¥_kW_true",
        ]

        stage1_metrics = []
        fig1, axes1 = plt.subplots(2, 3, figsize=(18, 10))
        axes1 = axes1.flatten()

        for idx, tgt in enumerate(stage1_targets_for_plot):
            actual = train_targets_true[tgt]
            pred = stage1_oof[tgt]
            valid_mask = (~actual.isna()) & (~pd.Series(pred).isna())
            actual = actual[valid_mask]
            pred = pred[valid_mask]

            if actual.empty:
                axes1[idx].text(0.5, 0.5, "ë°ì´í„° ì—†ìŒ", ha="center", va="center")
                axes1[idx].set_axis_off()
                continue

            mae = mean_absolute_error(actual, pred)
            r2 = r2_score(actual, pred)
            stage1_metrics.append({"target": tgt, "mae": mae, "r2": r2})

            min_val = min(actual.min(), pred.min())
            max_val = max(actual.max(), pred.max())
            diag = np.linspace(min_val, max_val, 100)

            axes1[idx].scatter(
                actual,
                pred,
                s=10,
                alpha=0.35,
                color="#4A90E2",
                edgecolors="none",
            )
            axes1[idx].plot(diag, diag, "--", color="#D0021B", label="Perfect")
            axes1[idx].set_title(f"{tgt}\nMAE={mae:.2f}, RÂ²={r2:.4f}")
            axes1[idx].set_xlabel("ì‹¤ì œê°’")
            axes1[idx].set_ylabel("ì˜ˆì¸¡ê°’")
            axes1[idx].legend(loc="upper left")
            axes1[idx].grid(alpha=0.3)

        fig1.suptitle("â–¡ Stage 1: 6ê°œ íƒ€ê²Ÿ ì˜ˆì¸¡ í’ˆì§ˆ (ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’)", fontsize=16, y=0.98)
        save_fig(fig1, output_dir / "stage1_target_performance.png")

        if stage1_metrics:
            stage1_summary = pd.DataFrame(stage1_metrics).sort_values("mae")
            stage1_summary.to_csv(output_dir / "stage1_performance_summary.csv", index=False)

        # PF(ì—­ë¥ ) ì¢…í•© ë¶„ì„ ëŒ€ì‹œë³´ë“œ
        pf_base = pd.DataFrame(
            {
                "ì‹œê°„": train["ì‹œê°„"],
                "ì›”": train["ì›”"],
                "PF_recalc": train["PF_recalc"],
                "ì˜ˆì¸¡_ì—­ë¥ ": train["ì§€ìƒì—­ë¥ (%)"],
                "ì‹¤ì œ_ì—­ë¥ ": train_targets_true["ì§€ìƒì—­ë¥ (%)"],
                "ì „ê¸°ìš”ê¸ˆ(ì›)": y_all,
                "ìš”ê¸ˆì ìš©ì „ë ¥_true": train_targets_true["ìš”ê¸ˆì ìš©ì „ë ¥_kW_true"],
            }
        ).dropna(subset=["ì‹œê°„", "ì‹¤ì œ_ì—­ë¥ "])

        pf_bins = pd.cut(
            pf_base["ì‹¤ì œ_ì—­ë¥ "],
            bins=[0, 80, 85, 90, 94, 110],
            labels=["ìœ„í—˜(<80)", "ê²½ê³ (80-85)", "ì£¼ì˜(85-90)", "ì–‘í˜¸(90-94)", "ìš°ìˆ˜(94+)"],
            right=False,
        )
        pf_base["ì—­ë¥ êµ¬ê°„"] = pf_bins

        hourly_pf = (
            pf_base.groupby("ì‹œê°„")[["PF_recalc", "ì‹¤ì œ_ì—­ë¥ ", "ì˜ˆì¸¡_ì—­ë¥ "]]
            .mean()
            .rename(columns={"PF_recalc": "PF ì¬ê³„ì‚°"})
        )

        pf_group = pf_base.groupby("ì—­ë¥ êµ¬ê°„").agg(
            ë°ì´í„°ìˆ˜=("ì‹¤ì œ_ì—­ë¥ ", "count"),
            í‰ê· ìš”ê¸ˆ=("ì „ê¸°ìš”ê¸ˆ(ì›)", "mean"),
            í‰ê· PF=("ì‹¤ì œ_ì—­ë¥ ", "mean"),
        )

        fig2, axes2 = plt.subplots(2, 2, figsize=(18, 12))

        hourly_pf.plot(ax=axes2[0, 0], marker="o")
        axes2[0, 0].axhline(94, color="#F5A623", linestyle="--", linewidth=1.4, label="ê¸°ì¤€ 94%")
        axes2[0, 0].axhline(90, color="#D0021B", linestyle="--", linewidth=1.4, label="ë²•ì  90%")
        axes2[0, 0].set_title("ì‹œê°„ëŒ€ë³„ í‰ê·  ì—­ë¥  ë¹„êµ")
        axes2[0, 0].set_xlabel("ì‹œê°„")
        axes2[0, 0].set_ylabel("ì—­ë¥  (%)")
        axes2[0, 0].legend(loc="lower right")
        axes2[0, 0].grid(alpha=0.3)

        axes2[0, 1].bar(pf_group.index.astype(str), pf_group["ë°ì´í„°ìˆ˜"], color="#4A90E2", alpha=0.7, label="ë°ì´í„° ìˆ˜")
        axes2[0, 1].set_ylabel("ë°ì´í„° ìˆ˜")
        axes2[0, 1].set_xlabel("ì—­ë¥  êµ¬ê°„")
        axes2[0, 1].tick_params(axis="x", rotation=20)
        axes2[0, 1].set_title("ì—­ë¥  êµ¬ê°„ë³„ ë¶„í¬ & í‰ê·  ìš”ê¸ˆ")
        ax2_twin = axes2[0, 1].twinx()
        ax2_twin.plot(
            pf_group.index.astype(str),
            pf_group["í‰ê· ìš”ê¸ˆ"],
            color="#F5A623",
            marker="o",
            label="í‰ê·  ìš”ê¸ˆ",
        )
        ax2_twin.set_ylabel("í‰ê·  ìš”ê¸ˆ (ì›)")

        scatter = axes2[1, 0].scatter(
            pf_base["ì‹¤ì œ_ì—­ë¥ "],
            pf_base["PF_recalc"],
            c=pf_base["ì „ê¸°ìš”ê¸ˆ(ì›)"],
            cmap="viridis",
            alpha=0.35,
            s=10,
        )
        axes2[1, 0].plot([50, 110], [50, 110], "--", color="#D0021B", linewidth=1.2)
        axes2[1, 0].set_xlim(50, 110)
        axes2[1, 0].set_ylim(50, 110)
        axes2[1, 0].set_title("PF ì¬ê³„ì‚° vs ì‹¤ì œ ì§€ìƒì—­ë¥  (ìƒ‰ìƒ: ìš”ê¸ˆ)")
        axes2[1, 0].set_xlabel("ì‹¤ì œ ì§€ìƒì—­ë¥  (%)")
        axes2[1, 0].set_ylabel("PF ì¬ê³„ì‚° (%)")
        cbar = plt.colorbar(scatter, ax=axes2[1, 0])
        cbar.set_label("ì „ê¸°ìš”ê¸ˆ(ì›)")

        pf_group["í‰ê· ìš”ê¸ˆ"].plot.barh(
            ax=axes2[1, 1],
            color=["#D0021B", "#F5A623", "#F8E71C", "#7ED321", "#417505"],
            alpha=0.8,
        )
        axes2[1, 1].set_title("ì—­ë¥  ë¶€ì¡±í­ë³„ í‰ê·  ìš”ê¸ˆ")
        axes2[1, 1].set_xlabel("í‰ê·  ì „ê¸°ìš”ê¸ˆ (ì›)")
        axes2[1, 1].set_ylabel("ì—­ë¥  êµ¬ê°„")

        fig2.suptitle("â–¡ ì—­ë¥ (PF) ì¢…í•© ë¶„ì„", fontsize=16, y=0.98)
        save_fig(fig2, output_dir / "pf_overview.png")

        # Stage2 ì˜ˆì¸¡ í’ˆì§ˆ ë° ì˜¤ì°¨ íŒ¨í„´ ë¶„ì„
        stage2_idx = oof_valid_idx
        stage2_eval = pd.DataFrame(
            {
                "ì‹¤ì œ_ì „ê¸°ìš”ê¸ˆ": y_all.loc[stage2_idx],
                "ì˜ˆì¸¡_ì „ê¸°ìš”ê¸ˆ": oof_pred_final,
            },
            index=stage2_idx,
        )
        stage2_eval["ì˜¤ì°¨"] = stage2_eval["ì˜ˆì¸¡_ì „ê¸°ìš”ê¸ˆ"] - stage2_eval["ì‹¤ì œ_ì „ê¸°ìš”ê¸ˆ"]
        stage2_eval["ì ˆëŒ€ì˜¤ì°¨"] = stage2_eval["ì˜¤ì°¨"].abs()

        stage2_context = stage2_eval.join(
            train.loc[
                stage2_idx,
                [
                    "ì›”",
                    "ì‹œê°„",
                    "ìš”ì¼",
                    "ì£¼ë§ì—¬ë¶€",
                    "tou_relative_price",
                    "tou_load_index",
                    "PF_recalc",
                    "ìš”ê¸ˆì ìš©ì „ë ¥_kW",
                ],
            ]
        )
        stage2_context["ì‹¤ì œ_ì§€ìƒì—­ë¥ "] = train_targets_true.loc[stage2_idx, "ì§€ìƒì—­ë¥ (%)"]
        stage2_context["ì—­ë¥ êµ¬ê°„"] = pf_base.loc[stage2_idx, "ì—­ë¥ êµ¬ê°„"]

        hourly_fee = stage2_context.groupby("ì‹œê°„")[["ì‹¤ì œ_ì „ê¸°ìš”ê¸ˆ", "ì˜ˆì¸¡_ì „ê¸°ìš”ê¸ˆ"]].mean()
        hourly_fee["TOU ê°€ê²©"] = stage2_context.groupby("ì‹œê°„")["tou_relative_price"].mean()

        tou_mae = (
            stage2_context.groupby("tou_load_index")
            .apply(lambda df: mean_absolute_error(df["ì‹¤ì œ_ì „ê¸°ìš”ê¸ˆ"], df["ì˜ˆì¸¡_ì „ê¸°ìš”ê¸ˆ"]))
            .rename({1: "LIGHT", 2: "MID", 3: "MAX"})
        )

        pf_mae = (
            stage2_context.dropna(subset=["ì—­ë¥ êµ¬ê°„"])
            .groupby("ì—­ë¥ êµ¬ê°„")
            .apply(lambda df: mean_absolute_error(df["ì‹¤ì œ_ì „ê¸°ìš”ê¸ˆ"], df["ì˜ˆì¸¡_ì „ê¸°ìš”ê¸ˆ"]))
            .reindex(pf_group.index)
        )

        month_hour_mae = (
            stage2_context.groupby(["ì›”", "ì‹œê°„"])["ì ˆëŒ€ì˜¤ì°¨"].mean().unstack(fill_value=np.nan)
        )

        top_errors = stage2_context.sort_values("ì ˆëŒ€ì˜¤ì°¨", ascending=False).head(8)

        fig3 = plt.figure(figsize=(18, 14))
        gs = fig3.add_gridspec(3, 2, height_ratios=[1, 1, 1.1])

        ax3_1 = fig3.add_subplot(gs[0, 0])
        hourly_fee[["ì‹¤ì œ_ì „ê¸°ìš”ê¸ˆ", "ì˜ˆì¸¡_ì „ê¸°ìš”ê¸ˆ"]].plot(ax=ax3_1, marker="o")
        ax3_1.set_title("ì‹œê°„ëŒ€ë³„ í‰ê·  ì „ê¸°ìš”ê¸ˆ (ì‹¤ì œ vs ì˜ˆì¸¡)")
        ax3_1.set_xlabel("ì‹œê°„")
        ax3_1.set_ylabel("í‰ê·  ì „ê¸°ìš”ê¸ˆ (ì›)")
        ax3_1.grid(alpha=0.3)
        ax3_1.xaxis.set_major_locator(MaxNLocator(integer=True))
        ax3_1_2 = ax3_1.twinx()
        ax3_1_2.bar(
            hourly_fee.index,
            hourly_fee["TOU ê°€ê²©"],
            alpha=0.2,
            color="#F5A623",
            label="í‰ê·  TOU ìƒëŒ€ê°€ê²©",
        )
        ax3_1_2.set_ylabel("TOU ìƒëŒ€ ê°€ê²©")

        ax3_2 = fig3.add_subplot(gs[0, 1])
        tou_mae.plot.bar(color=["#50E3C2", "#F8E71C", "#D0021B"], ax=ax3_2)
        ax3_2.set_title("TOU ë¶€í•˜ êµ¬ê°„ë³„ ì˜ˆì¸¡ ì˜¤ì°¨ (MAE)")
        ax3_2.set_xlabel("TOU êµ¬ê°„")
        ax3_2.set_ylabel("MAE (ì›)")

        ax3_3 = fig3.add_subplot(gs[1, 0])
        stage2_eval["ì˜¤ì°¨"].plot.hist(
            bins=60,
            ax=ax3_3,
            color="#4A90E2",
            alpha=0.75,
            edgecolor="white",
        )
        ax3_3.axvline(stage2_eval["ì˜¤ì°¨"].mean(), color="#D0021B", linestyle="--", label="í‰ê·  ì˜¤ì°¨")
        ax3_3.axvline(0, color="#417505", linestyle="-.", label="ì˜¤ì°¨=0")
        ax3_3.set_title(f"ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„í¬ (Std={stage2_eval['ì˜¤ì°¨'].std():.0f})")
        ax3_3.set_xlabel("ì˜ˆì¸¡ ì˜¤ì°¨ (ì˜ˆì¸¡ - ì‹¤ì œ)")
        ax3_3.set_ylabel("ë¹ˆë„")
        ax3_3.legend()

        ax3_4 = fig3.add_subplot(gs[1, 1])
        sns.heatmap(
            month_hour_mae,
            cmap="YlOrRd",
            ax=ax3_4,
            cbar_kws={"label": "MAE (ì›)"},
        )
        ax3_4.set_title("ì›”-ì‹œê°„ëŒ€ë³„ í‰ê·  MAE Heatmap")
        ax3_4.set_xlabel("ì‹œê°„")
        ax3_4.set_ylabel("ì›”")

        ax3_5 = fig3.add_subplot(gs[2, 0])
        pf_mae.plot.barh(color="#BD10E0", ax=ax3_5)
        ax3_5.set_title("ì—­ë¥  êµ¬ê°„ë³„ ì „ê¸°ìš”ê¸ˆ MAE")
        ax3_5.set_xlabel("MAE (ì›)")
        ax3_5.set_ylabel("ì—­ë¥  êµ¬ê°„")

        ax3_6 = fig3.add_subplot(gs[2, 1])
        ax3_6.axis("off")
        table_data = top_errors[
            ["ì‹¤ì œ_ì „ê¸°ìš”ê¸ˆ", "ì˜ˆì¸¡_ì „ê¸°ìš”ê¸ˆ", "ì˜¤ì°¨", "ì›”", "ì‹œê°„", "tou_load_index", "ì£¼ë§ì—¬ë¶€"]
        ].copy()
        table_data["ì˜¤ì°¨"] = table_data["ì˜¤ì°¨"].round(0).astype(int)
        table_data["ì‹¤ì œ_ì „ê¸°ìš”ê¸ˆ"] = table_data["ì‹¤ì œ_ì „ê¸°ìš”ê¸ˆ"].round(0).astype(int)
        table_data["ì˜ˆì¸¡_ì „ê¸°ìš”ê¸ˆ"] = table_data["ì˜ˆì¸¡_ì „ê¸°ìš”ê¸ˆ"].round(0).astype(int)
        table = ax3_6.table(
            cellText=table_data.values,
            colLabels=[
                "ì‹¤ì œ",
                "ì˜ˆì¸¡",
                "ì˜¤ì°¨",
                "ì›”",
                "ì‹œê°„",
                "TOU",
                "ì£¼ë§",
            ],
            loc="center",
            cellLoc="center",
        )
        table.scale(1, 1.4)
        ax3_6.set_title("ìƒìœ„ ì˜ˆì¸¡ ì˜¤ì°¨ ìƒ˜í”Œ", pad=20)

        fig3.suptitle("â–¡ ì˜¤ì°¨ íŒ¨í„´ ì¢…í•© ë¶„ì„", fontsize=16, y=0.99)
        save_fig(fig3, output_dir / "stage2_error_dashboard.png")

        # Stage2 ë³€ìˆ˜ ì¤‘ìš”ë„ ê³„ì‚°
        stage2_full_models = {}
        importance_frames = []
        X_all_hgb = X_all.rename(columns=lambda x: str(x).replace("[", "").replace("]", ""))

        for name, base in base_models.items():
            model = base.__class__(**base.get_params())
            if name == "hgb":
                model.fit(X_all_hgb, y_all_log)
            else:
                model.fit(X_all, y_all_log)
            stage2_full_models[name] = model

            if hasattr(model, "feature_importances_"):
                importance_frames.append(
                    pd.DataFrame(
                        {
                            "feature": X_all.columns,
                            "importance": model.feature_importances_,
                            "model": name.upper(),
                        }
                    )
                )

        if importance_frames:
            importance_df = pd.concat(importance_frames, ignore_index=True)
            agg_importance = (
                importance_df.groupby("feature")["importance"].mean().sort_values(ascending=False)
            )

            fig4, ax4 = plt.subplots(figsize=(12, 10))
            top_imp = agg_importance.head(20).sort_values()
            sns.barplot(x=top_imp.values, y=top_imp.index, ax=ax4, palette="Blues_d")
            ax4.set_title("Stage2 í‰ê·  ë³€ìˆ˜ ì¤‘ìš”ë„ Top 20 (Tree ê¸°ë°˜ ëª¨ë¸ í‰ê· )")
            ax4.set_xlabel("í‰ê·  ì¤‘ìš”ë„")
            ax4.set_ylabel("Feature")
            save_fig(fig4, output_dir / "stage2_feature_importance.png")

            importance_df.to_csv(output_dir / "stage2_feature_importance_raw.csv", index=False)

        # SHAP ë¶„ì„ (ê°€ëŠ¥í•  ê²½ìš°)
        try:
            import shap

            shap_sample = X_all.sample(n=min(3000, len(X_all)), random_state=42)
            shap_model = stage2_full_models.get("lgb")

            if shap_model is not None:
                explainer = shap.TreeExplainer(shap_model)
                shap_values = explainer.shap_values(shap_sample, check_additivity=False)
                if isinstance(shap_values, list):
                    shap_values = shap_values[0]

                shap.summary_plot(shap_values, shap_sample, show=False, plot_type="bar")
                fig = plt.gcf()
                fig.set_size_inches(10, 8)
                save_fig(fig, output_dir / "stage2_shap_summary_bar.png")

                shap.summary_plot(shap_values, shap_sample, show=False)
                fig = plt.gcf()
                fig.set_size_inches(12, 8)
                save_fig(fig, output_dir / "stage2_shap_summary_beeswarm.png")
        except ImportError as exc:
            print(f"âš ï¸ SHAP íŒ¨í‚¤ì§€ ë¯¸ì„¤ì¹˜ë¡œ SHAP ê·¸ë˜í”„ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤: {exc}")

        # í•™ìŠµëœ ëª¨ë¸ ë° ì „ì²˜ë¦¬ ê°ì²´ í”¼í´ ì €ì¥
        try:
            import pickle
        except ImportError as exc:
            print(f"âš ï¸ pickle ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ì–´ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ ì €ì¥í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {exc}")
        else:
            artifacts_dir = Path("models") / "artifacts"
            artifacts_dir.mkdir(parents=True, exist_ok=True)

            # Stage1 ì „ì²´ ë°ì´í„° ì¬í•™ìŠµ í›„ ì €ì¥ (ì‹¤ì œ ì˜ˆì¸¡ìš©)
            stage1_trained = {}
            for tgt, base_model in stage1_models.items():
                full_model = base_model.__class__(**base_model.get_params())
                target_series = train_targets_true[tgt].copy()
                use_log1p = tgt == "ìš”ê¸ˆì ìš©ì „ë ¥_kW_true"
                y_train = np.log1p(target_series) if use_log1p else target_series
                full_model.fit(train[feat_s1], y_train)
                stage1_trained[tgt] = {
                    "estimator": full_model,
                    "use_log1p": use_log1p,
                }

            stage1_payload = {
                "models": stage1_trained,
                "feature_names": feat_s1,
                "targets": targets_s1,
            }
            with open(artifacts_dir / "stage1_models.pkl", "wb") as f:
                pickle.dump(stage1_payload, f)

            # Stage2 ìŠ¤íƒœí‚¹ ëª¨ë¸ ë° ë©”íƒ€ ëŸ¬ë„ˆ ì €ì¥
            stage2_payload = {
                "base_models": stage2_full_models,
                "meta_model": meta_learner,
                "feature_names": feat_s2,
                "hgb_feature_names": list(X_all_hgb.columns),
                "base_model_order": list(stage2_full_models.keys()),
                "target_transform": "log1p",
            }
            with open(artifacts_dir / "stage2_ensemble.pkl", "wb") as f:
                pickle.dump(stage2_payload, f)

            # ì¸ì½”ë” ë° ê¸°íƒ€ ì „ì²˜ë¦¬ ìì› ì €ì¥
            preprocess_payload = {
                "label_encoders": {
                    "ì‘ì—…ìœ í˜•": le_job,
                    "tou_price_code": le_tou,
                    "ì‹œê°„_ì‘ì—…ìœ í˜•": le_tj,
                },
                "constants": {
                    "REF_DATE": REF_DATE,
                    "MAX_PRICE": MAX_PRICE,
                    "MID_PRICE": MID_PRICE,
                    "LIGHT_PRICE": LIGHT_PRICE,
                },
                "feature_sets": {
                    "stage1": feat_s1,
                    "stage2": feat_s2,
                },
            }
            with open(artifacts_dir / "preprocess_assets.pkl", "wb") as f:
                pickle.dump(preprocess_payload, f)

            print(f"ğŸ’¾ ëª¨ë¸ ë° ì „ì²˜ë¦¬ ì•„í‹°íŒ©íŠ¸ë¥¼ '{artifacts_dir}' ê²½ë¡œì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
